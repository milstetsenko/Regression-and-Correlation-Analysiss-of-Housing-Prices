# Import useful packages
import pandas
pandas.set_option('max_rows', 10)
import numpy as np
import pandas as pd
from scipy import stats
import matplotlib.pyplot as plt
import statsmodels.api as statsmodels # useful stats package with regression functions
import seaborn as sns # very nice plotting package

# style settings
sns.set(color_codes=True, font_scale = 2)
sns.set_style("darkgrid")

# import and print data
data = pd.read_csv("kc_house_data.csv")
data = pd.DataFrame(data)
data
analysis = data[['price','bedrooms', 'bathrooms','sqft_living', 'sqft_basement', 'condition', 'yr_built']]

#plotting a heatmap to define the correlations
#definfing the reight potential variables
analysis1 = data[['bedrooms', 'bathrooms','sqft_living', 'sqft_basement', 'condition', 'yr_built']]
analysis = data[['price','bedrooms', 'bathrooms','sqft_living', 'sqft_basement', 'condition', 'yr_built']]
#reducing the half of the data - the top triangle fo the graph to take away the redundancy
corr = analysis1.corr()
mask = np.zeros(corr.shape, dtype=bool)
mask[np.triu_indices(len(mask))] = True

#plotting the heatmap

ax = sns.heatmap(corr, vmin=-1, vmax=1, center=0, cmap="YlGnBu", mask = mask, square=True)
ax.set_xticklabels(
    ax.get_xticklabels(),
    rotation=45,
    horizontalalignment='right');
    
#simple regression
def simple_regression(column_x, column_y):
    #this function computes the R-squared value, the regression line equation, and plots
    #dataviz crucial for confirming the conditions for the OSL
    #this dataviz is the normality and the constant variability of the residuals 



simple_regression ('bathrooms', 'bedrooms')
simple_regression ('yr_built', 'sqft_living')
#pairplot cretaes scatterplots for all the variables we are investigating. 
#It is useful to prove the conditions for the OLS
analysis = data[['price','bedrooms', 'bathrooms','sqft_living', 'sqft_basement', 'condition', 'yr_built']]
sns.pairplot(analysis)

plt.plot()
#paorplotting to identify other non-linear correlations
analysis3 = data[['price','bedrooms','sqft_living', 'sqft_basement', 'condition']]
sns.pairplot(analysis3)

plt.plot()

#checking the linearity of correlation conditions for OLS using the simple_regression function
simple_regression ('bedrooms', 'price')

#checking the linearity of correlation conditions for OLS using the simple_regression function
simple_regression ('sqft_living', 'price')

#checking the linearity of correlation conditions for OLS using the simple_regression function
simple_regression ('sqft_basement', 'price')

#checking the linearity of correlation conditions for OLS using the simple_regression function
simple_regression ('condition', 'price')

def mult_regression(column_x, column_y):
    ''' this function checks two conditions for building the model using the graphsand outputs the regression 
    model with all the necessary stats for inferencing the results of the model.'''

    # If there is only one predictor variable, plot the regression line
    if len(column_x)==1:
        plt.figure()
        sns.regplot(x=column_x[0], y=column_y, data=data, marker="+",fit_reg=True,color='green')

    # define predictors X and response Y:
    X = analysis[column_x]
    X = statsmodels.add_constant(X)
    Y = analysis[column_y]

    # construct model:
    global regressionmodel 
    regressionmodel = statsmodels.OLS(Y,X).fit() # OLS = "ordinary least squares"

    # residual plot:
    plt.figure()
    residualplot = sns.residplot(x=regressionmodel.predict(), y=regressionmodel.resid, color='blue')
    residualplot.set(xlabel='Fitted values for '+column_y, ylabel='Residuals')
    residualplot.set_title('Residuals vs Fitted values',fontweight='bold',fontsize=14)

    # Normal Probability plot:
    qqplot = statsmodels.qqplot(regressionmodel.resid,fit=True,line='45')
    qqplot.suptitle("Normal Probability (\"QQ\") Plot for Residuals",fontweight='bold',fontsize=14, color = 'red')
    
#building the model with footage of the basement
mult_regression(['bedrooms','sqft_living', 'yr_built'],'price')
regressionmodel.summary()
    

    # fit the regression line 
    X = statsmodels.add_constant(data[column_x])
    Y = analysis[column_y]
    regressionmodel = statsmodels.OLS(Y,X).fit() #ordinary least squares

    # necessary paramateres to construct the regression line, rounded to 2 decimal
    Rsquared = round(regressionmodel.rsquared,2)
    slope = round(regressionmodel.params[1],2)
    intercept = round(regressionmodel.params[0],2)

    # plotting the resifuals, and the scatterplot to check the conditions:
    fig, (ax1, ax2) = plt.subplots(ncols=2, sharex=True, figsize=(12,4))
    sns.regplot(x=column_x, y=column_y, data=data, marker="+", ax=ax1) # scatter plot for linearity 
    sns.residplot(x=column_x, y=column_y, data=data, ax=ax2) # residual plot for constant variance
    ax2.set(ylabel='Residuals')
    ax2.set_ylim(min(regressionmodel.resid)-1,max(regressionmodel.resid)+1)
    plt.figure() # histogram for the normality of the residuals
    sns.distplot(regressionmodel.resid, kde=False, axlabel='Residuals', color='red') # histogram

    # outputing the necessary values.
    print("R-squared = ",Rsquared)
    print("Regression equation: "+column_y+" = ",slope,"* "+column_x+" + ",intercept)
    
